{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e481c2b2",
   "metadata": {},
   "source": [
    "# Apache Kafka Avan\u00e7ado \u2014 Notebook \u00danico (Colab)\n",
    "\n",
    "Este notebook cont\u00e9m **10 slides avan\u00e7ados**, cada um com **c\u00f3digo execut\u00e1vel** no Google Colab.\n",
    "\n",
    "> **Importante:** Execute as c\u00e9lulas **na ordem**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0e8be5",
   "metadata": {},
   "source": [
    "## Slide 0 \u2014 Setup Kafka (KRaft, single-node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea380012",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, subprocess, pathlib, re, time\n",
    "\n",
    "# Install Java 8 (Required for Kafka)\n",
    "def sh(cmd):\n",
    "    print(f\"$ {cmd}\")\n",
    "    out = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    if out.returncode != 0:\n",
    "        print(out.stdout)\n",
    "        print(out.stderr)\n",
    "        raise RuntimeError(cmd)\n",
    "    return out.stdout\n",
    "\n",
    "if not pathlib.Path(\"/usr/lib/jvm/java-8-openjdk-amd64\").exists():\n",
    "    print(\"Installing Java 8...\")\n",
    "    sh(\"apt-get install openjdk-8-jdk-headless -qq > /dev/null\")\n",
    "    os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "\n",
    "KAFKA_VERSION = \"3.6.1\"\n",
    "SCALA_VERSION = \"2.13\"\n",
    "KAFKA_TGZ = f\"kafka_{SCALA_VERSION}-{KAFKA_VERSION}.tgz\"\n",
    "KAFKA_DIR = f\"kafka_{SCALA_VERSION}-{KAFKA_VERSION}\"\n",
    "\n",
    "# function sh moved up\n",
    "\n",
    "if not pathlib.Path(KAFKA_DIR).exists():\n",
    "    sh(f\"wget -q https://downloads.apache.org/kafka/{KAFKA_VERSION}/{KAFKA_TGZ}\")\n",
    "    sh(f\"tar -xzf {KAFKA_TGZ}\")\n",
    "\n",
    "os.environ[\"KAFKA_HOME\"] = str(pathlib.Path(KAFKA_DIR).resolve())\n",
    "print(\"KAFKA_HOME =\", os.environ[\"KAFKA_HOME\"])\n",
    "\n",
    "kraft_cfg = pathlib.Path(KAFKA_DIR) / \"config\" / \"kraft\" / \"server.properties\"\n",
    "cfg = kraft_cfg.read_text()\n",
    "cfg = re.sub(r\"^listeners=.*$\", \"listeners=PLAINTEXT://:9092,CONTROLLER://:9093\", cfg, flags=re.M)\n",
    "cfg = re.sub(r\"^advertised.listeners=.*$\", \"advertised.listeners=PLAINTEXT://127.0.0.1:9092\", cfg, flags=re.M)\n",
    "cfg = re.sub(r\"^log.dirs=.*$\", \"log.dirs=/tmp/kafka-logs\", cfg, flags=re.M)\n",
    "kraft_cfg.write_text(cfg)\n",
    "\n",
    "cluster_id = sh(f\"{KAFKA_DIR}/bin/kafka-storage.sh random-uuid\").strip()\n",
    "sh(f\"{KAFKA_DIR}/bin/kafka-storage.sh format -t {cluster_id} -c {kraft_cfg} >/dev/null\")\n",
    "print(\"Kafka preparado (KRaft).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80478f47",
   "metadata": {},
   "source": [
    "## Slide 0.1 \u2014 Subir Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7086f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import subprocess, os, time, pathlib\n",
    "\n",
    "KAFKA_DIR = os.environ[\"KAFKA_HOME\"]\n",
    "kraft_cfg = pathlib.Path(KAFKA_DIR) / \"config\" / \"kraft\" / \"server.properties\"\n",
    "\n",
    "kafka_proc = subprocess.Popen(\n",
    "    [f\"{KAFKA_DIR}/bin/kafka-server-start.sh\", str(kraft_cfg)],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "time.sleep(3)\n",
    "for _ in range(15):\n",
    "    line = kafka_proc.stdout.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    print(line.rstrip())\n",
    "\n",
    "print(\"Kafka em execu\u00e7\u00e3o.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416cb78",
   "metadata": {},
   "source": [
    "## Slide 0.2 \u2014 Cliente Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbdb231",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install kafka-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7cd35c",
   "metadata": {},
   "source": [
    "## Slide 1 \u2014 Kafka como Log Distribu\u00eddo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6de948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from kafka import KafkaProducer, KafkaConsumer\n",
    "\n",
    "topic = \"s1_log\"\n",
    "producer = KafkaProducer(bootstrap_servers=\"127.0.0.1:9092\")\n",
    "\n",
    "for i in range(5):\n",
    "    producer.send(topic, f\"evento-{i}\".encode())\n",
    "producer.flush()\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "    topic,\n",
    "    bootstrap_servers=\"127.0.0.1:9092\",\n",
    "    auto_offset_reset=\"earliest\",\n",
    "    enable_auto_commit=False,\n",
    "    consumer_timeout_ms=2000\n",
    ")\n",
    "\n",
    "for m in consumer:\n",
    "    print(m.offset, m.value.decode())\n",
    "consumer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdfb0ad",
   "metadata": {},
   "source": [
    "## Slide 2 \u2014 Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760597a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import subprocess, os\n",
    "KAFKA_DIR = os.environ[\"KAFKA_HOME\"]\n",
    "topic = \"s2_partitions\"\n",
    "\n",
    "subprocess.run([\n",
    "    f\"{KAFKA_DIR}/bin/kafka-topics.sh\",\n",
    "    \"--bootstrap-server\",\"127.0.0.1:9092\",\n",
    "    \"--create\",\"--topic\",topic,\n",
    "    \"--partitions\",\"3\",\n",
    "    \"--replication-factor\",\"1\"\n",
    "], check=True)\n",
    "\n",
    "subprocess.run([\n",
    "    f\"{KAFKA_DIR}/bin/kafka-topics.sh\",\n",
    "    \"--bootstrap-server\",\"127.0.0.1:9092\",\n",
    "    \"--describe\",\"--topic\",topic\n",
    "], check=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6211da92",
   "metadata": {},
   "source": [
    "## Slide 3 \u2014 Sem\u00e2ntica de Entrega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85effb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from kafka import KafkaProducer\n",
    "import json, time\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=\"127.0.0.1:9092\",\n",
    "    acks=\"all\",\n",
    "    retries=5\n",
    ")\n",
    "\n",
    "producer.send(\"s3_delivery\", json.dumps({\n",
    "    \"id\":1,\"evento\":\"pagamento\",\"ts\":time.time()\n",
    "}).encode())\n",
    "producer.flush()\n",
    "\n",
    "print(\"Evento enviado com acks=all.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f657921",
   "metadata": {},
   "source": [
    "## Slide 4 \u2014 Performance (batch + compress\u00e3o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b21bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from kafka import KafkaProducer\n",
    "import time, json, random\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=\"127.0.0.1:9092\",\n",
    "    linger_ms=50,\n",
    "    batch_size=64000,\n",
    "    compression_type=\"gzip\"\n",
    ")\n",
    "\n",
    "t0 = time.time()\n",
    "for i in range(2000):\n",
    "    producer.send(\"s4_perf\", json.dumps({\"i\":i,\"x\":random.random()}).encode())\n",
    "producer.flush()\n",
    "print(\"Tempo:\", time.time()-t0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb36e6f8",
   "metadata": {},
   "source": [
    "## Slide 5 \u2014 Particionamento por Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e7a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from kafka import KafkaProducer, KafkaConsumer\n",
    "\n",
    "producer = KafkaProducer(bootstrap_servers=\"127.0.0.1:9092\")\n",
    "for i in range(10):\n",
    "    producer.send(\"s5_keys\", key=b\"user-42\", value=f\"msg-{i}\".encode())\n",
    "producer.flush()\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "    \"s5_keys\",\n",
    "    bootstrap_servers=\"127.0.0.1:9092\",\n",
    "    auto_offset_reset=\"earliest\",\n",
    "    consumer_timeout_ms=2000\n",
    ")\n",
    "\n",
    "for m in consumer:\n",
    "    print(m.partition, m.offset, m.key.decode(), m.value.decode())\n",
    "consumer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6a1963",
   "metadata": {},
   "source": [
    "## Slide 6 \u2014 Consumer Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4684a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from kafka import KafkaProducer\n",
    "producer = KafkaProducer(bootstrap_servers=\"127.0.0.1:9092\")\n",
    "\n",
    "for i in range(20):\n",
    "    producer.send(\"s6_group\", f\"evento-{i}\".encode())\n",
    "producer.flush()\n",
    "\n",
    "print(\"Produzido para consumer group.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4af4c4f",
   "metadata": {},
   "source": [
    "## Slide 7 \u2014 Replay de Offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d376aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from kafka import KafkaConsumer\n",
    "import time\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "    \"s7_replay\",\n",
    "    bootstrap_servers=\"127.0.0.1:9092\",\n",
    "    auto_offset_reset=\"earliest\",\n",
    "    enable_auto_commit=False\n",
    ")\n",
    "\n",
    "for i, m in enumerate(consumer):\n",
    "    print(\"Lido:\", m.offset, m.value.decode())\n",
    "    if i==4:\n",
    "        break\n",
    "\n",
    "consumer.commit()\n",
    "consumer.seek_to_beginning()\n",
    "\n",
    "for i, m in enumerate(consumer):\n",
    "    print(\"Replay:\", m.offset, m.value.decode())\n",
    "    if i==4:\n",
    "        break\n",
    "\n",
    "consumer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdf705e",
   "metadata": {},
   "source": [
    "## Slide 8 \u2014 Stateful Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b95677",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from kafka import KafkaConsumer\n",
    "from collections import defaultdict\n",
    "import json, time\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "    \"s8_stateful\",\n",
    "    bootstrap_servers=\"127.0.0.1:9092\",\n",
    "    auto_offset_reset=\"earliest\",\n",
    "    value_deserializer=lambda b: json.loads(b.decode()),\n",
    "    consumer_timeout_ms=10000\n",
    ")\n",
    "\n",
    "counts = defaultdict(int)\n",
    "start = time.time()\n",
    "\n",
    "for m in consumer:\n",
    "    counts[m.value[\"tipo\"]] += 1\n",
    "    if time.time()-start > 5:\n",
    "        print(dict(counts))\n",
    "        counts.clear()\n",
    "        start = time.time()\n",
    "\n",
    "consumer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da31ca7",
   "metadata": {},
   "source": [
    "## Slide 9 \u2014 Observabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da9aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import subprocess, os\n",
    "KAFKA_DIR = os.environ[\"KAFKA_HOME\"]\n",
    "\n",
    "subprocess.run([\n",
    "    f\"{KAFKA_DIR}/bin/kafka-consumer-groups.sh\",\n",
    "    \"--bootstrap-server\",\"127.0.0.1:9092\",\n",
    "    \"--all-groups\",\"--describe\"\n",
    "], check=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e873964a",
   "metadata": {},
   "source": [
    "## Slide 10 \u2014 CDC (Evento de Banco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb124a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from kafka import KafkaProducer, KafkaConsumer\n",
    "import json, time\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=\"127.0.0.1:9092\",\n",
    "    value_serializer=lambda d: json.dumps(d).encode()\n",
    ")\n",
    "\n",
    "producer.send(\"s10_cdc\", {\n",
    "    \"op\":\"u\",\n",
    "    \"before\":{\"id\":10,\"status\":\"pendente\"},\n",
    "    \"after\":{\"id\":10,\"status\":\"pago\"},\n",
    "    \"ts\":int(time.time()*1000)\n",
    "})\n",
    "producer.flush()\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "    \"s10_cdc\",\n",
    "    bootstrap_servers=\"127.0.0.1:9092\",\n",
    "    auto_offset_reset=\"earliest\",\n",
    "    value_deserializer=lambda b: json.loads(b.decode()),\n",
    "    consumer_timeout_ms=2000\n",
    ")\n",
    "\n",
    "for m in consumer:\n",
    "    print(m.value)\n",
    "consumer.close()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}