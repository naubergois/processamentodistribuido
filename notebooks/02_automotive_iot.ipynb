{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo 2: Automotivo - Sensores IoT de Ve\u00edculos\n",
    "\n",
    "Este notebook demonstra o processamento distribu\u00eddo de dados de sensores de ve\u00edculos usando **Dask**.\n",
    "\n",
    "**Cen\u00e1rio**: Analisar dados de uma frota de ve\u00edculos (velocidade, RPM, temperatura do \u00f3leo) para identificar comportamentos de dire\u00e7\u00e3o agressiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configura\u00e7\u00e3o do Ambiente\n",
    "Instala\u00e7\u00e3o do Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar Java\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "\n",
    "# Baixar e Instalar Spark\n",
    "!wget https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz && tar xf spark-3.5.0-bin-hadoop3.tgz\n",
    "\n",
    "# Baixar e Instalar Kafka\n",
    "!wget https://archive.apache.org/dist/kafka/3.6.1/kafka_2.13-3.6.1.tgz && tar xf kafka_2.13-3.6.1.tgz\n",
    "\n",
    "# Instalar pacotes Python\n",
    "!pip install -q findspark pyspark kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q dask[complete] distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "# Iniciar um cluster Dask local\n",
    "client = Client()\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simulador de Dados\n",
    "Gerar grandes arquivos CSV simulando logs de telemetria de 1000 ve\u00edculos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import os\n",
    "\n",
    "# Criar diret\u00f3rio para dados\n",
    "os.makedirs('vehicle_data', exist_ok=True)\n",
    "\n",
    "def generate_vehicle_logs(file_id):\n",
    "    num_records = 10000\n",
    "    df = pd.DataFrame({\n",
    "        'vehicle_id': np.random.randint(1, 1001, num_records),\n",
    "        'speed_kmh': np.random.normal(80, 20, num_records),\n",
    "        'rpm': np.random.normal(3000, 1000, num_records),\n",
    "        'oil_temp': np.random.normal(90, 10, num_records),\n",
    "        'timestamp': pd.date_range(start='2024-01-01', periods=num_records, freq='s')\n",
    "    })\n",
    "    # Introduzir anomalias (dire\u00e7\u00e3o agressiva)\n",
    "    df.loc[df['speed_kmh'] > 140, 'aggressive_flag'] = 1\n",
    "    df.loc[df['speed_kmh'] <= 140, 'aggressive_flag'] = 0\n",
    "    \n",
    "    df.to_csv(f'vehicle_data/log_{file_id}.csv', index=False)\n",
    "\n",
    "# Gerar 20 arquivos CSV em paralelo \u00e9 desnecess\u00e1rio aqui, vamos gerar serialmente pois \u00e9 r\u00e1pido\n",
    "print(\"Gerando dados simulados...\")\n",
    "for i in range(20):\n",
    "    generate_vehicle_logs(i)\n",
    "print(\"Dados gerados em 'vehicle_data/'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Processamento Distribu\u00eddo com Dask\n",
    "Ler todos os arquivos CSV como um \u00fanico Dask DataFrame e calcular estat\u00edsticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler m\u00faltiplos CSVs (Lazy Evaluation)\n",
    "ddf = dd.read_csv('vehicle_data/log_*.csv')\n",
    "\n",
    "# Visualizar primeiras linhas\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma\u00e7\u00e3o: Calcular m\u00e9dia de velocidade por ve\u00edculo\n",
    "avg_speed = ddf.groupby('vehicle_id')['speed_kmh'].mean()\n",
    "\n",
    "# Filtro: Ve\u00edculos com m\u00e9dia de velocidade muito alta\n",
    "fast_drivers = avg_speed[avg_speed > 110]\n",
    "\n",
    "# A\u00e7\u00e3o: Computar resultados (aqui o Dask distribui o trabalho)\n",
    "result = fast_drivers.compute()\n",
    "\n",
    "print(f\"Ve\u00edculos r\u00e1pidos detectados: {len(result)}\")\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An\u00e1lise mais complexa: Correlacionar RPM com Temperatura do \u00d3leo\n",
    "correlation = ddf[['rpm', 'oil_temp']].corr().compute()\n",
    "print(\"Matriz de Correla\u00e7\u00e3o:\")\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza\n",
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}